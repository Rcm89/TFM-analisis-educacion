{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Configuración del driver de Selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Maximiza la ventana del navegador\n",
    "driver.maximize_window()\n",
    "\n",
    "# URL objetivo\n",
    "url = \"https://www.universidades.gob.es/listado-de-universidades/\"\n",
    "\n",
    "def scrape_universidades():\n",
    "    # Abre la URL\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # Pulsar el botón de aceptar cookies\n",
    "    try:\n",
    "        cookies_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"#moove_gdpr_cookie_info_bar > div > div > div.moove-gdpr-button-holder > button.mgbutton.moove-gdpr-infobar-allow-all.gdpr-fbo-0\")))\n",
    "        cookies_button.click()\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo pulsar el botón de cookies: \", e)\n",
    "\n",
    "    # Espera a que cargue la sección de comunidades autónomas\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"accordion\")))\n",
    "\n",
    "    # Encuentra los botones de las comunidades autónomas\n",
    "    comunidades = driver.find_elements(By.CSS_SELECTOR, \".accordion .accordion-item .accordion-header button\")\n",
    "\n",
    "    data = []  # Lista para almacenar los datos\n",
    "\n",
    "    for i, comunidad in enumerate(comunidades):\n",
    "        try:\n",
    "            # Hacer clic en cada comunidad autónoma\n",
    "            ActionChains(driver).move_to_element(comunidad).click(comunidad).perform()\n",
    "\n",
    "            # Esperar a que la sección se expanda\n",
    "            time.sleep(1)  # Tiempo de espera para asegurar que cargue\n",
    "\n",
    "            # Extraer el contenido HTML de la sección expandida\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            section = soup.select(f\".accordion .accordion-item:nth-of-type({i + 1}) .accordion-body\")\n",
    "\n",
    "            if section:\n",
    "                universidades = section[0].find_all(\"li\")  # Encuentra las universidades dentro de la sección\n",
    "\n",
    "                for universidad in universidades:\n",
    "                    comunidad_nombre = comunidad.text.strip()\n",
    "                    universidad_nombre = universidad.text.strip()\n",
    "                    data.append({\n",
    "                        \"Comunidad Autónoma\": comunidad_nombre,\n",
    "                        \"Universidad\": universidad_nombre\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando la comunidad {comunidad.text.strip()}: {e}\")\n",
    "\n",
    "    # Convertir los datos a un DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Ejecutar el scraping\n",
    "df_universidades = scrape_universidades()\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n",
    "\n",
    "# Mostrar los resultados\n",
    "df_universidades.to_csv(\"universidades_por_comunidad.csv\", index=False)\n",
    "print(\"Scraping completado. Datos guardados en 'universidades_por_comunidad.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
